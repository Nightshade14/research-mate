# research-mate
The research-mate would use a Contextual-RAG (Anthropic AI's latest research on RAG) to find and QA Research Papers. The project is scalable and hosted on AWS. The project leverages vector databases and cutting edge embedding compression techniques like BQ and BBQ to minimize latency and speed-up operations by storing embeddings in-memory.

## Technologies
- Server: Flask
- Cloud: AWS
- Vector DB: Pinecone
- LLM: Llama 3.2 8B
